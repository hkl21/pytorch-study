{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-05 *\n",
      "  2.2335  0.0000  2.2335\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "torch.Size([5, 3])\n",
      "\n",
      " 1.7485  1.6012  0.2780\n",
      " 1.1631  1.3468  0.9638\n",
      " 1.0520  0.8917  1.2721\n",
      " 0.8722  1.5753  1.1400\n",
      " 0.8203  1.1591  1.0109\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 1.7485  1.6012  0.2780\n",
      " 1.1631  1.3468  0.9638\n",
      " 1.0520  0.8917  1.2721\n",
      " 0.8722  1.5753  1.1400\n",
      " 0.8203  1.1591  1.0109\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n",
      "\n",
      " 1.7485  1.6012  0.2780\n",
      " 1.1631  1.3468  0.9638\n",
      " 1.0520  0.8917  1.2721\n",
      " 0.8722  1.5753  1.1400\n",
      " 0.8203  1.1591  1.0109\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "x = torch.rand(5, 3)\n",
    "print(x.size())\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y) # equivanlt with torch.add(x, y)\n",
    "# another way of representing it\n",
    "\n",
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y , out = result)\n",
    "print(result)\n",
    "\n",
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(y) # any operation that mutates a tensor in-place is post-fixed with an _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2954\n",
      "-1.7100\n",
      " 0.1119\n",
      " 1.7719\n",
      "[torch.FloatTensor of size 4]\n",
      "\n",
      "\n",
      " 1.3031 -0.0956  1.3588 -0.4359\n",
      "-1.5298 -0.0056  0.9964 -1.0561\n",
      " 0.5035 -1.2426 -0.1360 -0.8731\n",
      " 0.1515  0.4062  1.2872 -1.6249\n",
      "[torch.FloatTensor of size 4x4]\n",
      " \n",
      " 1.3031\n",
      "-0.0956\n",
      " 1.3588\n",
      "-0.4359\n",
      "-1.5298\n",
      "-0.0056\n",
      " 0.9964\n",
      "-1.0561\n",
      " 0.5035\n",
      "-1.2426\n",
      "-0.1360\n",
      "-0.8731\n",
      " 0.1515\n",
      " 0.4062\n",
      " 1.2872\n",
      "-1.6249\n",
      "[torch.FloatTensor of size 16]\n",
      " \n",
      " 1.3031 -0.0956  1.3588 -0.4359 -1.5298 -0.0056  0.9964 -1.0561\n",
      " 0.5035 -1.2426 -0.1360 -0.8731  0.1515  0.4062  1.2872 -1.6249\n",
      "[torch.FloatTensor of size 2x8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])\n",
    "# can use Numpy- like indexing\n",
    "\n",
    "# if i want to resize/reshape tensor, i can use torch.view\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8) # the size -1 is inferred from other dimensions\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "[1. 1. 1. 1. 1.]\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.FloatTensor of size 5]\n",
      " [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "a.add_(1)\n",
    "print(a , b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n",
      "\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      "[torch.DoubleTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "np.add(a, 1, out = a) # out = a argument에 의해서 넘파이 a로 부터 전달받은 텐서 b의 값도 변함\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (48) : no kernel image is available for execution on the device at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:301",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-de228342f040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# TODO: add tests for operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0m__radd__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (48) : no kernel image is available for execution on the device at /opt/conda/conda-bld/pytorch_1518244421288/work/torch/lib/THC/generated/../generic/THCTensorMathPointwise.cu:301"
     ]
    }
   ],
   "source": [
    "# tensors can be moved onto GPU using the .cuda method\n",
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
